{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Cleaning Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:25:08.383320Z",
     "start_time": "2020-03-23T20:25:08.377125Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:25:09.308891Z",
     "start_time": "2020-03-23T20:25:09.300952Z"
    }
   },
   "outputs": [],
   "source": [
    "file = \"data.txt\"\n",
    "with open(file, \"rt\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split words by spaces\n",
    "- doing this results in words being splitted but punctuation is preserved in words like **armor-like**, **vermin.**, **me?**, **couldn't**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:28:12.269445Z",
     "start_time": "2020-03-23T20:28:12.262099Z"
    }
   },
   "outputs": [],
   "source": [
    "words = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:28:12.440789Z",
     "start_time": "2020-03-23T20:28:12.424889Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dreams,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word\n",
       "0           One\n",
       "1      morning,\n",
       "2          when\n",
       "3        Gregor\n",
       "4         Samsa\n",
       "5          woke\n",
       "6          from\n",
       "7      troubled\n",
       "8       dreams,\n",
       "9            he"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'original_word': words[:100]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using regex\n",
    "- doing this eliminates the problems we had, but it transforms words like **couldn't** to **could** and **t** which is not nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:28:13.230770Z",
     "start_time": "2020-03-23T20:28:13.224340Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:28:13.607955Z",
     "start_time": "2020-03-23T20:28:13.591215Z"
    }
   },
   "outputs": [],
   "source": [
    "words = re.split(r'\\W+', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:28:14.342457Z",
     "start_time": "2020-03-23T20:28:14.324455Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>using regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning,</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troubled</td>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dreams,</td>\n",
       "      <td>dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word using regex\n",
       "0           One         One\n",
       "1      morning,     morning\n",
       "2          when        when\n",
       "3        Gregor      Gregor\n",
       "4         Samsa       Samsa\n",
       "5          woke        woke\n",
       "6          from        from\n",
       "7      troubled    troubled\n",
       "8       dreams,      dreams\n",
       "9            he          he"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['using regex'] = words[:100]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split by whitespace and remove punctuation\n",
    "- Words like **What's** becomes Whats, **armour-like** becomes armourlike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:28:20.473189Z",
     "start_time": "2020-03-23T20:28:20.467002Z"
    }
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T17:14:31.322951Z",
     "start_time": "2020-03-23T17:14:31.296144Z"
    }
   },
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "# prepare regex for char filtering\n",
    "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "# remove punctuation\n",
    "stripped = [re_punc.sub('', w) for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:02.853981Z",
     "start_time": "2020-03-23T20:30:02.836254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>using regex</th>\n",
       "      <th>punctuation removed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning,</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troubled</td>\n",
       "      <td>troubled</td>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dreams,</td>\n",
       "      <td>dreams</td>\n",
       "      <td>dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word using regex punctuation removed\n",
       "0           One         One                 One\n",
       "1      morning,     morning             morning\n",
       "2          when        when                when\n",
       "3        Gregor      Gregor              Gregor\n",
       "4         Samsa       Samsa               Samsa\n",
       "5          woke        woke                woke\n",
       "6          from        from                from\n",
       "7      troubled    troubled            troubled\n",
       "8       dreams,      dreams              dreams\n",
       "9            he          he                  he"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['punctuation removed'] =  words[:100]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize case\n",
    "- normalize the case by converting words to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:07.463745Z",
     "start_time": "2020-03-23T20:30:07.451836Z"
    }
   },
   "outputs": [],
   "source": [
    "words = text.split()\n",
    "lowercased = [w.lower() for w in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:33.069752Z",
     "start_time": "2020-03-23T20:30:33.051416Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>using regex</th>\n",
       "      <th>punctuation removed</th>\n",
       "      <th>lowered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning,</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>troubled</td>\n",
       "      <td>troubled</td>\n",
       "      <td>troubled</td>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dreams,</td>\n",
       "      <td>dreams</td>\n",
       "      <td>dreams</td>\n",
       "      <td>dreams,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word using regex punctuation removed   lowered\n",
       "0           One         One                 One       one\n",
       "1      morning,     morning             morning  morning,\n",
       "2          when        when                when      when\n",
       "3        Gregor      Gregor              Gregor    gregor\n",
       "4         Samsa       Samsa               Samsa     samsa\n",
       "5          woke        woke                woke      woke\n",
       "6          from        from                from      from\n",
       "7      troubled    troubled            troubled  troubled\n",
       "8       dreams,      dreams              dreams   dreams,\n",
       "9            he          he                  he        he"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lowered'] =  lowercased[:100]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:45.807480Z",
     "start_time": "2020-03-23T20:30:44.144313Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:47.620000Z",
     "start_time": "2020-03-23T20:30:47.613215Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:48.213398Z",
     "start_time": "2020-03-23T20:30:48.144747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize sentences\n",
    "sentences = sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:30:48.724670Z",
     "start_time": "2020-03-23T20:30:48.713158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One morning, when Gregor Samsa woke from troubled dreams, he found\\nhimself transformed in his bed into a horrible vermin.',\n",
       " 'He lay on\\nhis armour-like back, and if he lifted his head a little he could\\nsee his brown belly, slightly domed and divided by arches into stiff\\nsections.',\n",
       " 'The bedding was hardly able to cover it and seemed ready\\nto slide off any moment.',\n",
       " 'His many legs, pitifully thin compared\\nwith the size of the rest of him, waved about helplessly as he\\nlooked.',\n",
       " '\"What\\'s happened to me?\"',\n",
       " 'he thought.',\n",
       " \"It wasn't a dream.\",\n",
       " 'His room,\\na proper human room although a little too small, lay peacefully\\nbetween its four familiar walls.',\n",
       " 'A collection of textile samples\\nlay spread out on the table - Samsa was a travelling salesman - and\\nabove it there hung a picture that he had recently cut out of an\\nillustrated magazine and housed in a nice, gilded frame.',\n",
       " 'It showed\\na lady fitted out with a fur hat and fur boa who sat upright,\\nraising a heavy fur muff that covered the whole of her lower arm\\ntowards the viewer.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:18.062640Z",
     "start_time": "2020-03-23T20:32:17.873034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "words = word_tokenize(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:18.092692Z",
     "start_time": "2020-03-23T20:32:18.070213Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dreams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word\n",
       "0           One\n",
       "1       morning\n",
       "2             ,\n",
       "3          when\n",
       "4        Gregor\n",
       "5         Samsa\n",
       "6          woke\n",
       "7          from\n",
       "8      troubled\n",
       "9        dreams"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'original_word': words[:100]})\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering punctuations, stop words\n",
    "\n",
    "- Stop words are those words that do not contribute to meaning of phrase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:18.906677Z",
     "start_time": "2020-03-23T20:32:18.896051Z"
    }
   },
   "outputs": [],
   "source": [
    "# filter out puncutuations\n",
    "words = [w for w in words if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:19.676387Z",
     "start_time": "2020-03-23T20:32:19.657765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>punctuation filtered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>woke</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from</td>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>troubled</td>\n",
       "      <td>dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dreams</td>\n",
       "      <td>he</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word punctuation filtered\n",
       "0           One                  One\n",
       "1       morning              morning\n",
       "2             ,                 when\n",
       "3          when               Gregor\n",
       "4        Gregor                Samsa\n",
       "5         Samsa                 woke\n",
       "6          woke                 from\n",
       "7          from             troubled\n",
       "8      troubled               dreams\n",
       "9        dreams                   he"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"punctuation filtered\"] = words[:100]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:26.419046Z",
     "start_time": "2020-03-23T20:32:26.409504Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# filter out Stop words\n",
    "stops = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:26.690074Z",
     "start_time": "2020-03-23T20:32:26.678103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:28.607171Z",
     "start_time": "2020-03-23T20:32:28.556229Z"
    }
   },
   "outputs": [],
   "source": [
    "words = [w for w in words if not w in stops]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:48.772293Z",
     "start_time": "2020-03-23T20:32:48.765203Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"removed stopwords\"] = words[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:32:56.364978Z",
     "start_time": "2020-03-23T20:32:56.347585Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>punctuation filtered</th>\n",
       "      <th>removed stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "      <td>troubled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>woke</td>\n",
       "      <td>from</td>\n",
       "      <td>dreams</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from</td>\n",
       "      <td>troubled</td>\n",
       "      <td>found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>troubled</td>\n",
       "      <td>dreams</td>\n",
       "      <td>transformed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dreams</td>\n",
       "      <td>he</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word punctuation filtered removed stopwords\n",
       "0           One                  One               One\n",
       "1       morning              morning           morning\n",
       "2             ,                 when            Gregor\n",
       "3          when               Gregor             Samsa\n",
       "4        Gregor                Samsa              woke\n",
       "5         Samsa                 woke          troubled\n",
       "6          woke                 from            dreams\n",
       "7          from             troubled             found\n",
       "8      troubled               dreams       transformed\n",
       "9        dreams                   he               bed"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming \n",
    "- refers to process of reducing each word to its root or base., removal of suffixes like ing, ly, s etc by rule based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:33:06.356387Z",
     "start_time": "2020-03-23T20:33:06.078070Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# init stemmer\n",
    "porter_stemmer=PorterStemmer()\n",
    "stemmed_words=[porter_stemmer.stem(word=word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:33:30.082556Z",
     "start_time": "2020-03-23T20:33:30.062712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>punctuation filtered</th>\n",
       "      <th>removed stopwords</th>\n",
       "      <th>stemmed_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "      <td>troubled</td>\n",
       "      <td>troubl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>woke</td>\n",
       "      <td>from</td>\n",
       "      <td>dreams</td>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from</td>\n",
       "      <td>troubled</td>\n",
       "      <td>found</td>\n",
       "      <td>found</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>troubled</td>\n",
       "      <td>dreams</td>\n",
       "      <td>transformed</td>\n",
       "      <td>transform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dreams</td>\n",
       "      <td>he</td>\n",
       "      <td>bed</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word punctuation filtered removed stopwords stemmed_word\n",
       "0           One                  One               One          one\n",
       "1       morning              morning           morning         morn\n",
       "2             ,                 when            Gregor       gregor\n",
       "3          when               Gregor             Samsa        samsa\n",
       "4        Gregor                Samsa              woke         woke\n",
       "5         Samsa                 woke          troubled       troubl\n",
       "6          woke                 from            dreams        dream\n",
       "7          from             troubled             found        found\n",
       "8      troubled               dreams       transformed    transform\n",
       "9        dreams                   he               bed          bed"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['stemmed_word'] =  stemmed_words[:100]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "- Stemming and Lemmatization both generate the root form of the inflected words. The difference is that stem might not be an actual word whereas, lemma is an actual language word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:35:18.748931Z",
     "start_time": "2020-03-23T20:35:16.700926Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "# init lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_words=[lemmatizer.lemmatize(word=word,pos='v') for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-23T20:35:38.170177Z",
     "start_time": "2020-03-23T20:35:38.148117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_word</th>\n",
       "      <th>punctuation filtered</th>\n",
       "      <th>removed stopwords</th>\n",
       "      <th>stemmed_word</th>\n",
       "      <th>lemmatized_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>One</td>\n",
       "      <td>one</td>\n",
       "      <td>One</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morning</td>\n",
       "      <td>morn</td>\n",
       "      <td>morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>,</td>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>gregor</td>\n",
       "      <td>Gregor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when</td>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>samsa</td>\n",
       "      <td>Samsa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gregor</td>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "      <td>woke</td>\n",
       "      <td>wake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsa</td>\n",
       "      <td>woke</td>\n",
       "      <td>troubled</td>\n",
       "      <td>troubl</td>\n",
       "      <td>trouble</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>woke</td>\n",
       "      <td>from</td>\n",
       "      <td>dreams</td>\n",
       "      <td>dream</td>\n",
       "      <td>dream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from</td>\n",
       "      <td>troubled</td>\n",
       "      <td>found</td>\n",
       "      <td>found</td>\n",
       "      <td>find</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>troubled</td>\n",
       "      <td>dreams</td>\n",
       "      <td>transformed</td>\n",
       "      <td>transform</td>\n",
       "      <td>transform</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dreams</td>\n",
       "      <td>he</td>\n",
       "      <td>bed</td>\n",
       "      <td>bed</td>\n",
       "      <td>bed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  original_word punctuation filtered removed stopwords stemmed_word  \\\n",
       "0           One                  One               One          one   \n",
       "1       morning              morning           morning         morn   \n",
       "2             ,                 when            Gregor       gregor   \n",
       "3          when               Gregor             Samsa        samsa   \n",
       "4        Gregor                Samsa              woke         woke   \n",
       "5         Samsa                 woke          troubled       troubl   \n",
       "6          woke                 from            dreams        dream   \n",
       "7          from             troubled             found        found   \n",
       "8      troubled               dreams       transformed    transform   \n",
       "9        dreams                   he               bed          bed   \n",
       "\n",
       "  lemmatized_word  \n",
       "0             One  \n",
       "1         morning  \n",
       "2          Gregor  \n",
       "3           Samsa  \n",
       "4            wake  \n",
       "5         trouble  \n",
       "6           dream  \n",
       "7            find  \n",
       "8       transform  \n",
       "9             bed  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['lemmatized_word'] =  lemmatized_words[:100]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
